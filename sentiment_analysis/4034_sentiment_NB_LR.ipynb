{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "needed-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "EXTERNAL_DATA_COUNT = 30000\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-stand",
   "metadata": {},
   "source": [
    "#### Read labeled data from Stanford sentiment140 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "sustainable-exercise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sentiment140.csv\", \n",
    "                 names=['target', 'id', 'date', 'flag', 'user', 'text'],\n",
    "                 encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-tongue",
   "metadata": {},
   "source": [
    "This shows that values 0 and 4 exists for target, which symbolizes sentiment. \n",
    "From dataset description, 0 is neg and 4 is pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "every-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['target','text']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-drilling",
   "metadata": {},
   "source": [
    "The original dataset is very big (1.6 million entries). We have decided to reduce the dataset to <insert number> entries, with equal number of positive and negative entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "corporate-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(df)\n",
    "neg_df = df[df['target'] == 0].head(EXTERNAL_DATA_COUNT)\n",
    "pos_df = df1[df1['target'] == 4].head(EXTERNAL_DATA_COUNT)\n",
    "frames = [neg_df, pos_df]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-republic",
   "metadata": {},
   "source": [
    "Now, read manually labeled data from COVID topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "entire-copying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0     0.0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1     0.0  is upset that he can't update his Facebook by ...\n",
       "2     0.0  @Kenichan I dived many times for the ball. Man...\n",
       "3     0.0    my whole body feels itchy and like its on fire \n",
       "4     0.0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manual = pd.read_csv(\"manually_label_samples_labeled.csv\")\n",
    "\n",
    "#label the polarity of each entry for choosing entries with sentimentt\n",
    "df_manual.loc[df_manual.sentiment==-1,'sentiment']=4\n",
    "df_manual.loc[df_manual.sentiment==0,'polarity']=1\n",
    "df_manual.loc[df_manual.sentiment==4,'polarity']=1\n",
    "df_manual.loc[df_manual.sentiment==2,'polarity']=0\n",
    "df_manual = df_manual.loc[df_manual.polarity == 1]\n",
    "\n",
    "df_manual = df_manual[['text', 'sentiment']].copy()\n",
    "frames = [df, df_manual]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df.loc[df.sentiment==0,'target']=0\n",
    "df.loc[df.sentiment==4,'target']=4\n",
    "df.loc[df.sentiment==2,'target']=2\n",
    "\n",
    "df = df.drop('sentiment', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-notice",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-colony",
   "metadata": {},
   "source": [
    "First, regular expression to remove links and @s\n",
    "\n",
    "Next, spelling reduction (as stanford group proj, reduce huuuungry to huungry)\n",
    "\n",
    "Then, microtext normalization using netlinguo dictionary and emoji library\n",
    "\n",
    "Finally, lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "digital-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "netlingo = pd.read_csv(\"netlingo.csv\")\n",
    "#This netlingo csv is crawled from the netlinguo webpage\n",
    "\n",
    "netlingo_dict = dict(zip(netlingo.abbr, netlingo.meaning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "thirty-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization using spaCY\n",
    "spacy_nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "#Try to use GPU for faster processing\n",
    "gpu_preference = spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "transparent-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    prev_char = ' '\n",
    "    curr_char = ' '\n",
    "    consecutive_char_count = 0\n",
    "    position = 0\n",
    "    \n",
    "    text = emoji.demojize(text)\n",
    "    text = text.replace(\":\",\" \")\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    for token in text.split():\n",
    "        if token in netlingo_dict:\n",
    "            token = netlingo_dict.get(token)\n",
    "            #lemma here\n",
    "            for t in token: \n",
    "                doc = spacy_nlp(t)\n",
    "                tokens.append([t.lemma_ for t in doc][0])\n",
    "        else:\n",
    "            for char in token: \n",
    "                curr_char = char\n",
    "                if curr_char == prev_char:\n",
    "                    consecutive_char_count += 1\n",
    "                else:\n",
    "                    consecutive_char_count = 0\n",
    "                position += 1\n",
    "                prev_char = char\n",
    "                if consecutive_char_count > 1:\n",
    "                    position -= 1\n",
    "                    token =  token[:position] + token[position+1:] #remove char\n",
    "                    continue\n",
    "            #lemma here\n",
    "            doc = spacy_nlp(token)\n",
    "            tokens.append([token.lemma_ for token in doc][0])\n",
    "            \n",
    "            \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "frank-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "loaded-elevation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>aww that s a bummer you shoulda get david carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>be upset that he can t update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>I dive many time for the ball manage to save 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>my whole body feel itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>no it s not behave at all I m mad why be I her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>4.0</td>\n",
       "      <td>he s active again lol finally tapo na quaranti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>I just write this sentence when stalin say a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>work from home be fun until you re generate yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>africafactszone I m defend the corruption sa p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4.0</td>\n",
       "      <td>jk s quarantine be over yaaay have fun outside...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0       0.0  aww that s a bummer you shoulda get david carr...\n",
       "1       0.0  be upset that he can t update his facebook by ...\n",
       "2       0.0  I dive many time for the ball manage to save 5...\n",
       "3       0.0      my whole body feel itchy and like its on fire\n",
       "4       0.0  no it s not behave at all I m mad why be I her...\n",
       "..      ...                                                ...\n",
       "989     4.0  he s active again lol finally tapo na quaranti...\n",
       "992     0.0  I just write this sentence when stalin say a m...\n",
       "994     0.0  work from home be fun until you re generate yo...\n",
       "998     4.0  africafactszone I m defend the corruption sa p...\n",
       "999     4.0  jk s quarantine be over yaaay have fun outside...\n",
       "\n",
       "[60418 rows x 2 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-december",
   "metadata": {},
   "source": [
    "### Split training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "promising-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = list(df['text'])\n",
    "y = list(df['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-sister",
   "metadata": {},
   "source": [
    "### Create vectorizer using n-grams (n = 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "naked-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create a bag of words for only unigrams and bigrams\n",
    "cv = CountVectorizer(analyzer = 'word',ngram_range=(1,2))\n",
    "\n",
    "# convert training data to bag of words\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-variable",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "special-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.7695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# train naive bayes classifier\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_cv, y_train)\n",
    "\n",
    "# create predictions\n",
    "y_pred = clf_nb.predict(X_test_cv)\n",
    "\n",
    "# find f-1 score\n",
    "score = f1_score(y_test, y_pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "fundamental-audience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7726536262362811, 0.7691330779480346, 0.7686461435793841, None)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-interview",
   "metadata": {},
   "source": [
    "### Logistic Regression (MaxEnt) classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "defensive-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.7801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# train maxent (logistic)\n",
    "clf_lr = LogisticRegression(random_state=0, max_iter=300)\n",
    "clf_lr.fit(X_train_cv, y_train)\n",
    "\n",
    "# create predictions\n",
    "y_pred = clf_lr.predict(X_test_cv)\n",
    "\n",
    "# find f-1 score\n",
    "score = f1_score(y_test, y_pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "architectural-prague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7803899124815148, 0.7802281812125249, 0.7801201381993648, None)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-impossible",
   "metadata": {},
   "source": [
    "Now that training of both classifiers are done, we should move on to test the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-variable",
   "metadata": {},
   "source": [
    "### Test using labeled data that are used in training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-function",
   "metadata": {},
   "source": [
    "To examine the classifiers on sentiment classification only, we only choose the data entries with sentiment. Subjectivity classifiers are examined in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "korean-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply preprocessing on test data\n",
    "df_manual.text = df_manual.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "logical-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes in the right circumstance there be a case ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>currently down with covid admin two neighbour ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>why be that wretche woman dlaminizuma on tv bl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>while the number of people hospitalize with co...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tomw18105328 kamvtv laugh in pandemic shut down</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>he s active again lol finally tapo na quaranti...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>I just write this sentence when stalin say a m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>work from home be fun until you re generate yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>africafactszone I m defend the corruption sa p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>jk s quarantine be over yaaay have fun outside...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  sentiment\n",
       "0    yes in the right circumstance there be a case ...          0\n",
       "3    currently down with covid admin two neighbour ...          0\n",
       "6    why be that wretche woman dlaminizuma on tv bl...          0\n",
       "7    while the number of people hospitalize with co...          4\n",
       "9      tomw18105328 kamvtv laugh in pandemic shut down          0\n",
       "..                                                 ...        ...\n",
       "989  he s active again lol finally tapo na quaranti...          4\n",
       "992  I just write this sentence when stalin say a m...          0\n",
       "994  work from home be fun until you re generate yo...          0\n",
       "998  africafactszone I m defend the corruption sa p...          4\n",
       "999  jk s quarantine be over yaaay have fun outside...          4\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-collaboration",
   "metadata": {},
   "source": [
    "#### Multinomial NB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "increased-portfolio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.9139\n"
     ]
    }
   ],
   "source": [
    "test = list(df_manual['text'])\n",
    "ref = list(df_manual['sentiment'])\n",
    "test_cv = cv.transform(test)\n",
    "pred = clf_nb.predict(test_cv)\n",
    "\n",
    "#df_test['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "comparative-liberia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       266\n",
      "           4       0.94      0.82      0.87       152\n",
      "\n",
      "    accuracy                           0.91       418\n",
      "   macro avg       0.92      0.89      0.90       418\n",
      "weighted avg       0.92      0.91      0.91       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-project",
   "metadata": {},
   "source": [
    "#### Logistic Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "difficult-pierce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.9282\n"
     ]
    }
   ],
   "source": [
    "pred = clf_lr.predict(test_cv)\n",
    "\n",
    "#df_test['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "right-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       266\n",
      "           4       0.92      0.88      0.90       152\n",
      "\n",
      "    accuracy                           0.93       418\n",
      "   macro avg       0.93      0.92      0.92       418\n",
      "weighted avg       0.93      0.93      0.93       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-external",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "broadband-typing",
   "metadata": {},
   "source": [
    "### Test using labeled data that are not used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "established-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_json(\"manually_label_samples_test_labeled.json\", orient='record')\n",
    "\n",
    "df5.loc[df5.sentiment==-1,'sentiment']=4\n",
    "df5.loc[df5.sentiment==0,'polarity']=1\n",
    "df5.loc[df5.sentiment==4,'polarity']=1\n",
    "df5.loc[df5.sentiment==2,'polarity']=0\n",
    "\n",
    "df5 = df5.loc[df5.polarity == 1]\n",
    "df5.text = df5.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-personal",
   "metadata": {},
   "source": [
    "#### Multinomial NB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "congressional-preliminary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.7244\n"
     ]
    }
   ],
   "source": [
    "test = list(df5['text'])\n",
    "ref = list(df5['sentiment'])\n",
    "test_cv = cv.transform(test)\n",
    "pred = clf_nb.predict(test_cv)\n",
    "\n",
    "#df5['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "public-roman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80       104\n",
      "           4       0.60      0.54      0.57        52\n",
      "\n",
      "    accuracy                           0.72       156\n",
      "   macro avg       0.69      0.68      0.68       156\n",
      "weighted avg       0.72      0.72      0.72       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-observation",
   "metadata": {},
   "source": [
    "#### Logistic Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "unusual-grade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.7115\n"
     ]
    }
   ],
   "source": [
    "pred = clf_lr.predict(test_cv)\n",
    "\n",
    "#df5['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "subjective-harmony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78       104\n",
      "           4       0.56      0.63      0.59        52\n",
      "\n",
      "    accuracy                           0.71       156\n",
      "   macro avg       0.68      0.69      0.69       156\n",
      "weighted avg       0.72      0.71      0.72       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-monte",
   "metadata": {},
   "source": [
    "### Test using every labeled data in COVID topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "continuous-wilson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>geo</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes in the right circumstance there be a case ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>currently down with covid admin two neighbour ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>why be that wretche woman dlaminizuma on tv bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>while the number of people hospitalize with co...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tomw18105328 kamvtv laugh in pandemic shut down</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>greet stupid play with my human be a extreme e...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-02 15:52:57+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1.429572e+18</td>\n",
       "      <td>1.510284e+18</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>dailymailuk live with covid mean accept some s...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-30 08:20:01+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1.482627e+18</td>\n",
       "      <td>1.509083e+18</td>\n",
       "      <td>[social distancing]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>happy april avoid allfool standwithukraine sto...</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-04-01 10:59:29+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>6.172872e+08</td>\n",
       "      <td>1.509848e+18</td>\n",
       "      <td>[#wearamask]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>if there be more frequent access to testing me...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-02 06:18:24+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1.427558e+18</td>\n",
       "      <td>1.510140e+18</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>thank you to everyone out there continue to ma...</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-03-29 06:34:49+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1.437276e+18</td>\n",
       "      <td>1.508694e+18</td>\n",
       "      <td>[#wearamask]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  sentiment  \\\n",
       "0    yes in the right circumstance there be a case ...          0   \n",
       "3    currently down with covid admin two neighbour ...          0   \n",
       "6    why be that wretche woman dlaminizuma on tv bl...          0   \n",
       "7    while the number of people hospitalize with co...          4   \n",
       "9      tomw18105328 kamvtv laugh in pandemic shut down          0   \n",
       "..                                                 ...        ...   \n",
       "377  greet stupid play with my human be a extreme e...          0   \n",
       "380  dailymailuk live with covid mean accept some s...          0   \n",
       "387  happy april avoid allfool standwithukraine sto...          4   \n",
       "388  if there be more frequent access to testing me...          0   \n",
       "389  thank you to everyone out there continue to ma...          4   \n",
       "\n",
       "                   created_at lang     author_id            id  \\\n",
       "0                         NaT  NaN           NaN           NaN   \n",
       "3                         NaT  NaN           NaN           NaN   \n",
       "6                         NaT  NaN           NaN           NaN   \n",
       "7                         NaT  NaN           NaN           NaN   \n",
       "9                         NaT  NaN           NaN           NaN   \n",
       "..                        ...  ...           ...           ...   \n",
       "377 2022-04-02 15:52:57+00:00   en  1.429572e+18  1.510284e+18   \n",
       "380 2022-03-30 08:20:01+00:00   en  1.482627e+18  1.509083e+18   \n",
       "387 2022-04-01 10:59:29+00:00   en  6.172872e+08  1.509848e+18   \n",
       "388 2022-04-02 06:18:24+00:00   en  1.427558e+18  1.510140e+18   \n",
       "389 2022-03-29 06:34:49+00:00   en  1.437276e+18  1.508694e+18   \n",
       "\n",
       "                 keyword  geo  polarity  \n",
       "0                    NaN  NaN       NaN  \n",
       "3                    NaN  NaN       NaN  \n",
       "6                    NaN  NaN       NaN  \n",
       "7                    NaN  NaN       NaN  \n",
       "9                    NaN  NaN       NaN  \n",
       "..                   ...  ...       ...  \n",
       "377           [lockdown]  NaN       1.0  \n",
       "380  [social distancing]  NaN       1.0  \n",
       "387         [#wearamask]  NaN       1.0  \n",
       "388           [lockdown]  NaN       1.0  \n",
       "389         [#wearamask]  NaN       1.0  \n",
       "\n",
       "[574 rows x 9 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_manual, df5]\n",
    "df_test = pd.concat(frames)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-corporation",
   "metadata": {},
   "source": [
    "#### Multinomial NB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "proprietary-generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.8624\n"
     ]
    }
   ],
   "source": [
    "test = list(df_test['text'])\n",
    "ref = list(df_test['sentiment'])\n",
    "test_cv = cv.transform(test)\n",
    "pred = clf_nb.predict(test_cv)\n",
    "\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "exceptional-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       370\n",
      "           4       0.85      0.75      0.79       204\n",
      "\n",
      "    accuracy                           0.86       574\n",
      "   macro avg       0.86      0.84      0.85       574\n",
      "weighted avg       0.86      0.86      0.86       574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-adams",
   "metadata": {},
   "source": [
    "#### Logistic Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "laughing-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.8693\n"
     ]
    }
   ],
   "source": [
    "pred = clf_lr.predict(test_cv)\n",
    "\n",
    "#df5['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "protecting-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       370\n",
      "           4       0.82      0.81      0.82       204\n",
      "\n",
      "    accuracy                           0.87       574\n",
      "   macro avg       0.86      0.86      0.86       574\n",
      "weighted avg       0.87      0.87      0.87       574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-practitioner",
   "metadata": {},
   "source": [
    "### Now, applying this model to the set for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "excessive-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-253-a87e5541cfb1>:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clean_df = pd.read_csv(\"classfied_data_pol_final.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>keyword</th>\n",
       "      <th>geo</th>\n",
       "      <th>withheld</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-02 17:54:23+00:00</td>\n",
       "      <td>15066159</td>\n",
       "      <td>march#to#june#will#be#a#bit#sparse#for#sightin...</td>\n",
       "      <td>1510314716178046976</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-02 17:47:49+00:00</td>\n",
       "      <td>292619181</td>\n",
       "      <td>alan#interview#prime#minister#boris#johnson#an...</td>\n",
       "      <td>1510313065589481472</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-02 17:44:12+00:00</td>\n",
       "      <td>15720519</td>\n",
       "      <td>how#to#talk#to#your#kid#about#school#shooting#...</td>\n",
       "      <td>1510312154284630016</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-02 17:42:46+00:00</td>\n",
       "      <td>1280441028064018432</td>\n",
       "      <td>fat#loss#in#a#week#weight#loss#for#free#traini...</td>\n",
       "      <td>1510311792698101760</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-02 17:34:58+00:00</td>\n",
       "      <td>1449377983211450368</td>\n",
       "      <td>make#a#name#get#a#check#merchandise#royality#d...</td>\n",
       "      <td>1510309831005069312</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66857</th>\n",
       "      <td>2022-04-02 05:00:19+00:00</td>\n",
       "      <td>1307968835694125056</td>\n",
       "      <td>goddessphotosau#sure#do#a#new#hobby#come#out#o...</td>\n",
       "      <td>1510119915801309184</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66858</th>\n",
       "      <td>2022-04-02 05:00:01+00:00</td>\n",
       "      <td>2269577210</td>\n",
       "      <td>5#determine#the#strategy#for#pandemic#manageme...</td>\n",
       "      <td>1510119841281228800</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66859</th>\n",
       "      <td>2022-04-02 04:59:59+00:00</td>\n",
       "      <td>3493412003</td>\n",
       "      <td>an#old#story#but#think#about#this#again#now#th...</td>\n",
       "      <td>1510119833366675456</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66860</th>\n",
       "      <td>2022-04-02 04:59:53+00:00</td>\n",
       "      <td>1301866054839185408</td>\n",
       "      <td>tax#oz#even#then#his#wa#covid#0#forever#lockdo...</td>\n",
       "      <td>1510119806930145280</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66861</th>\n",
       "      <td>2022-04-02 04:59:42+00:00</td>\n",
       "      <td>370445156</td>\n",
       "      <td>observation#of#an#insomniac#live#on#a#main#roa...</td>\n",
       "      <td>1510119759643578368</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66862 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      created_at            author_id  \\\n",
       "0      2022-04-02 17:54:23+00:00             15066159   \n",
       "1      2022-04-02 17:47:49+00:00            292619181   \n",
       "2      2022-04-02 17:44:12+00:00             15720519   \n",
       "3      2022-04-02 17:42:46+00:00  1280441028064018432   \n",
       "4      2022-04-02 17:34:58+00:00  1449377983211450368   \n",
       "...                          ...                  ...   \n",
       "66857  2022-04-02 05:00:19+00:00  1307968835694125056   \n",
       "66858  2022-04-02 05:00:01+00:00           2269577210   \n",
       "66859  2022-04-02 04:59:59+00:00           3493412003   \n",
       "66860  2022-04-02 04:59:53+00:00  1301866054839185408   \n",
       "66861  2022-04-02 04:59:42+00:00            370445156   \n",
       "\n",
       "                                                    text                   id  \\\n",
       "0      march#to#june#will#be#a#bit#sparse#for#sightin...  1510314716178046976   \n",
       "1      alan#interview#prime#minister#boris#johnson#an...  1510313065589481472   \n",
       "2      how#to#talk#to#your#kid#about#school#shooting#...  1510312154284630016   \n",
       "3      fat#loss#in#a#week#weight#loss#for#free#traini...  1510311792698101760   \n",
       "4      make#a#name#get#a#check#merchandise#royality#d...  1510309831005069312   \n",
       "...                                                  ...                  ...   \n",
       "66857  goddessphotosau#sure#do#a#new#hobby#come#out#o...  1510119915801309184   \n",
       "66858  5#determine#the#strategy#for#pandemic#manageme...  1510119841281228800   \n",
       "66859  an#old#story#but#think#about#this#again#now#th...  1510119833366675456   \n",
       "66860  tax#oz#even#then#his#wa#covid#0#forever#lockdo...  1510119806930145280   \n",
       "66861  observation#of#an#insomniac#live#on#a#main#roa...  1510119759643578368   \n",
       "\n",
       "      lang                    keyword  geo withheld  polarity  \n",
       "0       en  ['#lockdown', 'lockdown']  NaN      NaN       1.0  \n",
       "1       en  ['#lockdown', 'lockdown']  NaN      NaN       0.0  \n",
       "2       en  ['#lockdown', 'lockdown']  NaN      NaN       0.0  \n",
       "3       en  ['#lockdown', 'lockdown']  NaN      NaN       0.0  \n",
       "4       en  ['#lockdown', 'lockdown']  NaN      NaN       0.0  \n",
       "...    ...                        ...  ...      ...       ...  \n",
       "66857   en               ['lockdown']  NaN      NaN       1.0  \n",
       "66858   en               ['lockdown']  NaN      NaN       0.0  \n",
       "66859   en               ['lockdown']  NaN      NaN       1.0  \n",
       "66860   en               ['lockdown']  NaN      NaN       1.0  \n",
       "66861   en               ['lockdown']  NaN      NaN       0.0  \n",
       "\n",
       "[66862 rows x 9 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_csv(\"classfied_data_pol_final.csv\")\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "valuable-somalia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>keyword</th>\n",
       "      <th>geo</th>\n",
       "      <th>withheld</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-02 17:54:23+00:00</td>\n",
       "      <td>15066159</td>\n",
       "      <td>march#to#june#will#be#a#bit#sparse#for#sightin...</td>\n",
       "      <td>1510314716178046976</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-04-02 17:20:37+00:00</td>\n",
       "      <td>1193612999803723776</td>\n",
       "      <td>I#recommend#everyone#to#watch#v#for#vendetta#i...</td>\n",
       "      <td>1510306220040761344</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', '#quarantine', 'coronavirus', 'q...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-04-02 17:01:41+00:00</td>\n",
       "      <td>1327891543596953600</td>\n",
       "      <td>shanghai#begin#second#stage#of#citywide#lockdo...</td>\n",
       "      <td>1510301454657110016</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-04-02 16:52:31+00:00</td>\n",
       "      <td>77123276</td>\n",
       "      <td>this#be#beyond#outrageous#those#poor#baby#shan...</td>\n",
       "      <td>1510299149236940800</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-04-02 16:47:03+00:00</td>\n",
       "      <td>1025960188057214976</td>\n",
       "      <td>child#concentration#camp#in#shanghai#these#chi...</td>\n",
       "      <td>1510297771739430912</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66854</th>\n",
       "      <td>2022-04-02 05:00:59+00:00</td>\n",
       "      <td>26940008</td>\n",
       "      <td>the#crisis#be#the#direct#result#of#covid#measu...</td>\n",
       "      <td>1510120083724673024</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66856</th>\n",
       "      <td>2022-04-02 05:00:24+00:00</td>\n",
       "      <td>1464991420561899520</td>\n",
       "      <td>big#april#fool#day#joke#be#the#6ixbuzz#post#ab...</td>\n",
       "      <td>1510119938492710912</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66857</th>\n",
       "      <td>2022-04-02 05:00:19+00:00</td>\n",
       "      <td>1307968835694125056</td>\n",
       "      <td>goddessphotosau#sure#do#a#new#hobby#come#out#o...</td>\n",
       "      <td>1510119915801309184</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66859</th>\n",
       "      <td>2022-04-02 04:59:59+00:00</td>\n",
       "      <td>3493412003</td>\n",
       "      <td>an#old#story#but#think#about#this#again#now#th...</td>\n",
       "      <td>1510119833366675456</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66860</th>\n",
       "      <td>2022-04-02 04:59:53+00:00</td>\n",
       "      <td>1301866054839185408</td>\n",
       "      <td>tax#oz#even#then#his#wa#covid#0#forever#lockdo...</td>\n",
       "      <td>1510119806930145280</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28087 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      created_at            author_id  \\\n",
       "0      2022-04-02 17:54:23+00:00             15066159   \n",
       "6      2022-04-02 17:20:37+00:00  1193612999803723776   \n",
       "8      2022-04-02 17:01:41+00:00  1327891543596953600   \n",
       "9      2022-04-02 16:52:31+00:00             77123276   \n",
       "10     2022-04-02 16:47:03+00:00  1025960188057214976   \n",
       "...                          ...                  ...   \n",
       "66854  2022-04-02 05:00:59+00:00             26940008   \n",
       "66856  2022-04-02 05:00:24+00:00  1464991420561899520   \n",
       "66857  2022-04-02 05:00:19+00:00  1307968835694125056   \n",
       "66859  2022-04-02 04:59:59+00:00           3493412003   \n",
       "66860  2022-04-02 04:59:53+00:00  1301866054839185408   \n",
       "\n",
       "                                                    text                   id  \\\n",
       "0      march#to#june#will#be#a#bit#sparse#for#sightin...  1510314716178046976   \n",
       "6      I#recommend#everyone#to#watch#v#for#vendetta#i...  1510306220040761344   \n",
       "8      shanghai#begin#second#stage#of#citywide#lockdo...  1510301454657110016   \n",
       "9      this#be#beyond#outrageous#those#poor#baby#shan...  1510299149236940800   \n",
       "10     child#concentration#camp#in#shanghai#these#chi...  1510297771739430912   \n",
       "...                                                  ...                  ...   \n",
       "66854  the#crisis#be#the#direct#result#of#covid#measu...  1510120083724673024   \n",
       "66856  big#april#fool#day#joke#be#the#6ixbuzz#post#ab...  1510119938492710912   \n",
       "66857  goddessphotosau#sure#do#a#new#hobby#come#out#o...  1510119915801309184   \n",
       "66859  an#old#story#but#think#about#this#again#now#th...  1510119833366675456   \n",
       "66860  tax#oz#even#then#his#wa#covid#0#forever#lockdo...  1510119806930145280   \n",
       "\n",
       "      lang                                            keyword  geo withheld  \\\n",
       "0       en                          ['#lockdown', 'lockdown']  NaN      NaN   \n",
       "6       en  ['#lockdown', '#quarantine', 'coronavirus', 'q...  NaN      NaN   \n",
       "8       en                          ['#lockdown', 'lockdown']  NaN      NaN   \n",
       "9       en                          ['#lockdown', 'lockdown']  NaN      NaN   \n",
       "10      en                          ['#lockdown', 'lockdown']  NaN      NaN   \n",
       "...    ...                                                ...  ...      ...   \n",
       "66854   en                                       ['lockdown']  NaN      NaN   \n",
       "66856   en                                       ['lockdown']  NaN      NaN   \n",
       "66857   en                                       ['lockdown']  NaN      NaN   \n",
       "66859   en                                       ['lockdown']  NaN      NaN   \n",
       "66860   en                                       ['lockdown']  NaN      NaN   \n",
       "\n",
       "       polarity  sentiment  \n",
       "0           1.0        4.0  \n",
       "6           1.0        0.0  \n",
       "8           1.0        0.0  \n",
       "9           1.0        0.0  \n",
       "10          1.0        0.0  \n",
       "...         ...        ...  \n",
       "66854       1.0        0.0  \n",
       "66856       1.0        0.0  \n",
       "66857       1.0        0.0  \n",
       "66859       1.0        0.0  \n",
       "66860       1.0        0.0  \n",
       "\n",
       "[28087 rows x 10 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.loc[clean_df.polarity==0,'sentiment']=2\n",
    "clean_df.loc[clean_df.polarity==1,'sentiment']=-1\n",
    "\n",
    "input_df = clean_df.loc[clean_df.polarity == 1]\n",
    "neutral_df = clean_df.loc[clean_df.polarity == 0]\n",
    "\n",
    "input_list = list(input_df['text'])\n",
    "input_cv = cv.transform(input_list)\n",
    "pred = clf_nb.predict(input_cv)\n",
    "\n",
    "sentiment = pred.tolist()\n",
    "input_df = input_df.assign(sentiment = sentiment)\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "superior-doubt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>keyword</th>\n",
       "      <th>geo</th>\n",
       "      <th>withheld</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-02 17:54:23+00:00</td>\n",
       "      <td>15066159</td>\n",
       "      <td>march#to#june#will#be#a#bit#sparse#for#sightin...</td>\n",
       "      <td>1510314716178046976</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-04-02 17:20:37+00:00</td>\n",
       "      <td>1193612999803723776</td>\n",
       "      <td>I#recommend#everyone#to#watch#v#for#vendetta#i...</td>\n",
       "      <td>1510306220040761344</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', '#quarantine', 'coronavirus', 'q...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-04-02 17:01:41+00:00</td>\n",
       "      <td>1327891543596953600</td>\n",
       "      <td>shanghai#begin#second#stage#of#citywide#lockdo...</td>\n",
       "      <td>1510301454657110016</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-04-02 16:52:31+00:00</td>\n",
       "      <td>77123276</td>\n",
       "      <td>this#be#beyond#outrageous#those#poor#baby#shan...</td>\n",
       "      <td>1510299149236940800</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-04-02 16:47:03+00:00</td>\n",
       "      <td>1025960188057214976</td>\n",
       "      <td>child#concentration#camp#in#shanghai#these#chi...</td>\n",
       "      <td>1510297771739430912</td>\n",
       "      <td>en</td>\n",
       "      <td>['#lockdown', 'lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66844</th>\n",
       "      <td>2022-04-02 05:02:50+00:00</td>\n",
       "      <td>350772690</td>\n",
       "      <td>more#than#l#o#c#a#t#I#o#n#000#banker#and#trade...</td>\n",
       "      <td>1510120548398891008</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66851</th>\n",
       "      <td>2022-04-02 05:01:15+00:00</td>\n",
       "      <td>1280478739793448960</td>\n",
       "      <td>how#the#key#of#sushant#s#room#go#miss#how#they...</td>\n",
       "      <td>1510120151978369024</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66855</th>\n",
       "      <td>2022-04-02 05:00:48+00:00</td>\n",
       "      <td>1314347140450193408</td>\n",
       "      <td>nmhrkssr#itsselfy#itsssr#as#per#I#know#1#ssr#p...</td>\n",
       "      <td>1510120039143276544</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66858</th>\n",
       "      <td>2022-04-02 05:00:01+00:00</td>\n",
       "      <td>2269577210</td>\n",
       "      <td>5#determine#the#strategy#for#pandemic#manageme...</td>\n",
       "      <td>1510119841281228800</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66861</th>\n",
       "      <td>2022-04-02 04:59:42+00:00</td>\n",
       "      <td>370445156</td>\n",
       "      <td>observation#of#an#insomniac#live#on#a#main#roa...</td>\n",
       "      <td>1510119759643578368</td>\n",
       "      <td>en</td>\n",
       "      <td>['lockdown']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66862 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      created_at            author_id  \\\n",
       "0      2022-04-02 17:54:23+00:00             15066159   \n",
       "6      2022-04-02 17:20:37+00:00  1193612999803723776   \n",
       "8      2022-04-02 17:01:41+00:00  1327891543596953600   \n",
       "9      2022-04-02 16:52:31+00:00             77123276   \n",
       "10     2022-04-02 16:47:03+00:00  1025960188057214976   \n",
       "...                          ...                  ...   \n",
       "66844  2022-04-02 05:02:50+00:00            350772690   \n",
       "66851  2022-04-02 05:01:15+00:00  1280478739793448960   \n",
       "66855  2022-04-02 05:00:48+00:00  1314347140450193408   \n",
       "66858  2022-04-02 05:00:01+00:00           2269577210   \n",
       "66861  2022-04-02 04:59:42+00:00            370445156   \n",
       "\n",
       "                                                    text                   id  \\\n",
       "0      march#to#june#will#be#a#bit#sparse#for#sightin...  1510314716178046976   \n",
       "6      I#recommend#everyone#to#watch#v#for#vendetta#i...  1510306220040761344   \n",
       "8      shanghai#begin#second#stage#of#citywide#lockdo...  1510301454657110016   \n",
       "9      this#be#beyond#outrageous#those#poor#baby#shan...  1510299149236940800   \n",
       "10     child#concentration#camp#in#shanghai#these#chi...  1510297771739430912   \n",
       "...                                                  ...                  ...   \n",
       "66844  more#than#l#o#c#a#t#I#o#n#000#banker#and#trade...  1510120548398891008   \n",
       "66851  how#the#key#of#sushant#s#room#go#miss#how#they...  1510120151978369024   \n",
       "66855  nmhrkssr#itsselfy#itsssr#as#per#I#know#1#ssr#p...  1510120039143276544   \n",
       "66858  5#determine#the#strategy#for#pandemic#manageme...  1510119841281228800   \n",
       "66861  observation#of#an#insomniac#live#on#a#main#roa...  1510119759643578368   \n",
       "\n",
       "      lang                                            keyword  geo withheld  \\\n",
       "0       en                          ['#lockdown', 'lockdown']  NaN      NaN   \n",
       "6       en  ['#lockdown', '#quarantine', 'coronavirus', 'q...  NaN      NaN   \n",
       "8       en                          ['#lockdown', 'lockdown']  NaN      NaN   \n",
       "9       en                          ['#lockdown', 'lockdown']  NaN      NaN   \n",
       "10      en                          ['#lockdown', 'lockdown']  NaN      NaN   \n",
       "...    ...                                                ...  ...      ...   \n",
       "66844   en                                       ['lockdown']  NaN      NaN   \n",
       "66851   en                                       ['lockdown']  NaN      NaN   \n",
       "66855   en                                       ['lockdown']  NaN      NaN   \n",
       "66858   en                                       ['lockdown']  NaN      NaN   \n",
       "66861   en                                       ['lockdown']  NaN      NaN   \n",
       "\n",
       "       polarity  sentiment  \n",
       "0           1.0        4.0  \n",
       "6           1.0        0.0  \n",
       "8           1.0        0.0  \n",
       "9           1.0        0.0  \n",
       "10          1.0        0.0  \n",
       "...         ...        ...  \n",
       "66844       0.0        2.0  \n",
       "66851       0.0        2.0  \n",
       "66855       0.0        2.0  \n",
       "66858       0.0        2.0  \n",
       "66861       0.0        2.0  \n",
       "\n",
       "[66862 rows x 10 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = [input_df, neutral_df]\n",
    "output_df = pd.concat(frame)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "apart-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_df.to_json(\"classified_twitter_data.json\", orient='records', indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "crazy-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_list = output_df.sentiment.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "lyric-voice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>keyword</th>\n",
       "      <th>geo</th>\n",
       "      <th>withheld</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-02 17:54:23+00:00</td>\n",
       "      <td>15066159</td>\n",
       "      <td>@andy_goodey March to June will be a bit spars...</td>\n",
       "      <td>1510314716178046976</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-02 17:47:49+00:00</td>\n",
       "      <td>292619181</td>\n",
       "      <td>Alan interviews Prime Minister Boris Johnson. ...</td>\n",
       "      <td>1510313065589481472</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-02 17:44:12+00:00</td>\n",
       "      <td>15720519</td>\n",
       "      <td>How To Talk To Your Kids About School Shooting...</td>\n",
       "      <td>1510312154284630016</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-02 17:42:46+00:00</td>\n",
       "      <td>1280441028064018432</td>\n",
       "      <td>FAT LOSS IN a WEEK  weight loss\\n FOR FREE TRA...</td>\n",
       "      <td>1510311792698101760</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-02 17:34:58+00:00</td>\n",
       "      <td>1449377983211450368</td>\n",
       "      <td>Making a name get a check merchandise ROYALITY...</td>\n",
       "      <td>1510309831005069312</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66857</th>\n",
       "      <td>2022-04-02 05:00:19+00:00</td>\n",
       "      <td>1307968835694125056</td>\n",
       "      <td>@RainMorgan33 @Goddessphotosau Sure did! A new...</td>\n",
       "      <td>1510119915801309184</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66858</th>\n",
       "      <td>2022-04-02 05:00:01+00:00</td>\n",
       "      <td>2269577210</td>\n",
       "      <td>@CBSNews 5/ determining the strategies for pan...</td>\n",
       "      <td>1510119841281228800</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66859</th>\n",
       "      <td>2022-04-02 04:59:59+00:00</td>\n",
       "      <td>3493412003</td>\n",
       "      <td>An old story, but thinking about this again no...</td>\n",
       "      <td>1510119833366675456</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66860</th>\n",
       "      <td>2022-04-02 04:59:53+00:00</td>\n",
       "      <td>1301866054839185408</td>\n",
       "      <td>@barbara32805432 @tax_oz Even then his wa covi...</td>\n",
       "      <td>1510119806930145280</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66861</th>\n",
       "      <td>2022-04-02 04:59:42+00:00</td>\n",
       "      <td>370445156</td>\n",
       "      <td>Observations of an insomniac living on a main ...</td>\n",
       "      <td>1510119759643578368</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66862 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at            author_id  \\\n",
       "0     2022-04-02 17:54:23+00:00             15066159   \n",
       "1     2022-04-02 17:47:49+00:00            292619181   \n",
       "2     2022-04-02 17:44:12+00:00             15720519   \n",
       "3     2022-04-02 17:42:46+00:00  1280441028064018432   \n",
       "4     2022-04-02 17:34:58+00:00  1449377983211450368   \n",
       "...                         ...                  ...   \n",
       "66857 2022-04-02 05:00:19+00:00  1307968835694125056   \n",
       "66858 2022-04-02 05:00:01+00:00           2269577210   \n",
       "66859 2022-04-02 04:59:59+00:00           3493412003   \n",
       "66860 2022-04-02 04:59:53+00:00  1301866054839185408   \n",
       "66861 2022-04-02 04:59:42+00:00            370445156   \n",
       "\n",
       "                                                    text                   id  \\\n",
       "0      @andy_goodey March to June will be a bit spars...  1510314716178046976   \n",
       "1      Alan interviews Prime Minister Boris Johnson. ...  1510313065589481472   \n",
       "2      How To Talk To Your Kids About School Shooting...  1510312154284630016   \n",
       "3      FAT LOSS IN a WEEK  weight loss\\n FOR FREE TRA...  1510311792698101760   \n",
       "4      Making a name get a check merchandise ROYALITY...  1510309831005069312   \n",
       "...                                                  ...                  ...   \n",
       "66857  @RainMorgan33 @Goddessphotosau Sure did! A new...  1510119915801309184   \n",
       "66858  @CBSNews 5/ determining the strategies for pan...  1510119841281228800   \n",
       "66859  An old story, but thinking about this again no...  1510119833366675456   \n",
       "66860  @barbara32805432 @tax_oz Even then his wa covi...  1510119806930145280   \n",
       "66861  Observations of an insomniac living on a main ...  1510119759643578368   \n",
       "\n",
       "      lang                keyword  geo withheld  sentiment  \n",
       "0       en  [#lockdown, lockdown]  NaN      NaN        4.0  \n",
       "1       en  [#lockdown, lockdown]  NaN      NaN        0.0  \n",
       "2       en  [#lockdown, lockdown]  NaN      NaN        0.0  \n",
       "3       en  [#lockdown, lockdown]  NaN      NaN        0.0  \n",
       "4       en  [#lockdown, lockdown]  NaN      NaN        0.0  \n",
       "...    ...                    ...  ...      ...        ...  \n",
       "66857   en             [lockdown]  NaN      NaN        2.0  \n",
       "66858   en             [lockdown]  NaN      NaN        2.0  \n",
       "66859   en             [lockdown]  NaN      NaN        2.0  \n",
       "66860   en             [lockdown]  NaN      NaN        2.0  \n",
       "66861   en             [lockdown]  NaN      NaN        2.0  \n",
       "\n",
       "[66862 rows x 9 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_json(\"cleaned_data.json\", orient='record')\n",
    "clean_df = clean_df.assign(sentiment = sentiment_list)\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "outstanding-luxury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How To Talk To Your Kids About School Shootings - Advice Offered By Psychologist And Award Winning Selfie Film Maker Barbara Becker Holstein https://t.co/OCPJq1Rset #bullying #lockdown https://t.co/k5WEyGv2kQ'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "clean_df.text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "characteristic-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_json(\"classified_twitter_data_final.json\", orient='records', indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-ridge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
