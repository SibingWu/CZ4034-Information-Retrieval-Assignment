{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "needed-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "EXTERNAL_DATA_COUNT = 750\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-stand",
   "metadata": {},
   "source": [
    "#### Read labeled data from IMDB rotten tomato movie review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "sustainable-exercise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'skip work to see it at the first opportunity...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when raj's family move to england to get invol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the clues are few and time is running out for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"fessenden continues to do interesting work ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>throughout this time , their lives have been e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>b\"has enough wit , energy and geniality to ple...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>patricia confides to her good-hearted maid mar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>today the mighty trident ssbns form a deterren...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>this first film , a deliberately allegorical v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>b'evokes a palpable sense of disconnection , m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  polarity\n",
       "0     b'skip work to see it at the first opportunity...         1\n",
       "1     when raj's family move to england to get invol...         0\n",
       "2     the clues are few and time is running out for ...         0\n",
       "3     b\"fessenden continues to do interesting work ,...         1\n",
       "4     throughout this time , their lives have been e...         0\n",
       "...                                                 ...       ...\n",
       "9995  b\"has enough wit , energy and geniality to ple...         1\n",
       "9996  patricia confides to her good-hearted maid mar...         0\n",
       "9997  today the mighty trident ssbns form a deterren...         0\n",
       "9998  this first film , a deliberately allegorical v...         0\n",
       "9999  b'evokes a palpable sense of disconnection , m...         1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"complete10000.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "outdoor-billion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'skip work to see it at the first opportunity...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"fessenden continues to do interesting work ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b\"as predictable as the outcome of a globetrot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'together , miller , kuras and the actresses ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b\"a lousy movie that's not merely unwatchable ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>b\"it's a lovely film with lovely performances ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>b\" . . . with the candy-like taste of it fadin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>b\"i loved looking at this movie . i just didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>b'graced with the kind of social texture and r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>b'features nonsensical and laughable plotting ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  polarity\n",
       "0     b'skip work to see it at the first opportunity...         1\n",
       "3     b\"fessenden continues to do interesting work ,...         1\n",
       "5     b\"as predictable as the outcome of a globetrot...         1\n",
       "7     b'together , miller , kuras and the actresses ...         1\n",
       "10    b\"a lousy movie that's not merely unwatchable ...         1\n",
       "...                                                 ...       ...\n",
       "1494  b\"it's a lovely film with lovely performances ...         1\n",
       "1496  b\" . . . with the candy-like taste of it fadin...         1\n",
       "1497  b\"i loved looking at this movie . i just didn'...         1\n",
       "1498  b'graced with the kind of social texture and r...         1\n",
       "1500  b'features nonsensical and laughable plotting ...         1\n",
       "\n",
       "[750 rows x 2 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df\n",
    "neg_df = df[df['polarity'] == 0].head(EXTERNAL_DATA_COUNT)\n",
    "pos_df = df1[df1['polarity'] == 1].head(EXTERNAL_DATA_COUNT)\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "heard-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>skip work to see it at the first opportunity ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fessenden continues to do interesting work , a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>as predictable as the outcome of a globetrotte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>together , miller , kuras and the actresses ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a lousy movie that's not merely unwatchable , ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>it's a lovely film with lovely performances by...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>. . . with the candy-like taste of it fading ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>i loved looking at this movie . i just didn't ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>graced with the kind of social texture and rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>features nonsensical and laughable plotting , ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  polarity\n",
       "0     skip work to see it at the first opportunity ....         1\n",
       "3     fessenden continues to do interesting work , a...         1\n",
       "5     as predictable as the outcome of a globetrotte...         1\n",
       "7     together , miller , kuras and the actresses ma...         1\n",
       "10    a lousy movie that's not merely unwatchable , ...         1\n",
       "...                                                 ...       ...\n",
       "1494  it's a lovely film with lovely performances by...         1\n",
       "1496   . . . with the candy-like taste of it fading ...         1\n",
       "1497  i loved looking at this movie . i just didn't ...         1\n",
       "1498  graced with the kind of social texture and rea...         1\n",
       "1500  features nonsensical and laughable plotting , ...         1\n",
       "\n",
       "[750 rows x 2 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_b(text):\n",
    "    text = str(text)[2:]\n",
    "    return text\n",
    "pos_df.text = pos_df.text.apply(remove_b)\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "rapid-writer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when raj's family move to england to get invol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the clues are few and time is running out for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>throughout this time , their lives have been e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a dark psychological drama , i love your work ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>after finding the plane and its crew torn to s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>it's a lovely film with lovely performances by...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>. . . with the candy-like taste of it fading ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>i loved looking at this movie . i just didn't ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>graced with the kind of social texture and rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>features nonsensical and laughable plotting , ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  polarity\n",
       "1     when raj's family move to england to get invol...         0\n",
       "2     the clues are few and time is running out for ...         0\n",
       "4     throughout this time , their lives have been e...         0\n",
       "6     a dark psychological drama , i love your work ...         0\n",
       "8     after finding the plane and its crew torn to s...         0\n",
       "...                                                 ...       ...\n",
       "1494  it's a lovely film with lovely performances by...         1\n",
       "1496   . . . with the candy-like taste of it fading ...         1\n",
       "1497  i loved looking at this movie . i just didn't ...         1\n",
       "1498  graced with the kind of social texture and rea...         1\n",
       "1500  features nonsensical and laughable plotting , ...         1\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [neg_df, pos_df]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-republic",
   "metadata": {},
   "source": [
    "Now, read manually labeled data from COVID topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "entire-copying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when raj's family move to england to get invol...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the clues are few and time is running out for ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>throughout this time , their lives have been e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a dark psychological drama , i love your work ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>after finding the plane and its crew torn to s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  polarity\n",
       "1  when raj's family move to england to get invol...       0.0\n",
       "2  the clues are few and time is running out for ...       0.0\n",
       "4  throughout this time , their lives have been e...       0.0\n",
       "6  a dark psychological drama , i love your work ...       0.0\n",
       "8  after finding the plane and its crew torn to s...       0.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manual = pd.read_csv(\"manually_label_samples_labeled.csv\")\n",
    "\n",
    "#label the polarity of each entry for choosing entries with sentimentt\n",
    "df_manual.loc[df_manual.sentiment==-1,'sentiment']=4\n",
    "df_manual.loc[df_manual.sentiment==0,'polarity']=1\n",
    "df_manual.loc[df_manual.sentiment==4,'polarity']=1\n",
    "df_manual.loc[df_manual.sentiment==2,'polarity']=0\n",
    "\n",
    "df_manual = df_manual[['text', 'polarity']].copy()\n",
    "frames = [df, df_manual]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-notice",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-colony",
   "metadata": {},
   "source": [
    "First, regular expression to remove links and @s\n",
    "\n",
    "Next, spelling reduction (as stanford group proj, reduce huuuungry to huungry)\n",
    "\n",
    "Then, microtext normalization using netlinguo dictionary and emoji library\n",
    "\n",
    "Finally, lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "digital-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "netlingo = pd.read_csv(\"netlingo.csv\")\n",
    "#This netlingo csv is crawled from the netlinguo webpage\n",
    "\n",
    "netlingo_dict = dict(zip(netlingo.abbr, netlingo.meaning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "thirty-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization using spaCY\n",
    "spacy_nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "#Try to use GPU for faster processing\n",
    "gpu_preference = spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "transparent-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    prev_char = ' '\n",
    "    curr_char = ' '\n",
    "    consecutive_char_count = 0\n",
    "    position = 0\n",
    "    \n",
    "    text = emoji.demojize(text)\n",
    "    text = text.replace(\":\",\" \")\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    for token in text.split():\n",
    "        if token in netlingo_dict:\n",
    "            token = netlingo_dict.get(token)\n",
    "            #lemma here\n",
    "            for t in token: \n",
    "                doc = spacy_nlp(t)\n",
    "                tokens.append([t.lemma_ for t in doc][0])\n",
    "        else:\n",
    "            for char in token: \n",
    "                curr_char = char\n",
    "                if curr_char == prev_char:\n",
    "                    consecutive_char_count += 1\n",
    "                else:\n",
    "                    consecutive_char_count = 0\n",
    "                position += 1\n",
    "                prev_char = char\n",
    "                if consecutive_char_count > 1:\n",
    "                    position -= 1\n",
    "                    token =  token[:position] + token[position+1:] #remove char\n",
    "                    continue\n",
    "            #lemma here\n",
    "            doc = spacy_nlp(token)\n",
    "            tokens.append([token.lemma_ for token in doc][0])\n",
    "            \n",
    "            \n",
    "    return \"#\".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "frank-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "loaded-elevation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when#raj#s#family#move#to#england#to#get#invol...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the#clue#be#few#and#time#be#run#out#for#the#st...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>throughout#this#time#their#live#have#be#entwin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a#dark#psychological#drama#I#love#your#work#ex...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>after#find#the#plane#and#its#crew#tear#to#shre...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>for#all#those#who#be#new#to#this#work#from#hom...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>full#stack#web#developer#remotework#remotejob#wfh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>where#will#collaboration#tool#for#hybridwork#g...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>africafactszone#I#m#defend#the#corruption#sa#p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>jk#s#quarantine#be#over#yaaay#have#fun#outside...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  polarity\n",
       "1    when#raj#s#family#move#to#england#to#get#invol...       0.0\n",
       "2    the#clue#be#few#and#time#be#run#out#for#the#st...       0.0\n",
       "4    throughout#this#time#their#live#have#be#entwin...       0.0\n",
       "6    a#dark#psychological#drama#I#love#your#work#ex...       0.0\n",
       "8    after#find#the#plane#and#its#crew#tear#to#shre...       0.0\n",
       "..                                                 ...       ...\n",
       "995  for#all#those#who#be#new#to#this#work#from#hom...       0.0\n",
       "996  full#stack#web#developer#remotework#remotejob#wfh       0.0\n",
       "997  where#will#collaboration#tool#for#hybridwork#g...       0.0\n",
       "998  africafactszone#I#m#defend#the#corruption#sa#p...       1.0\n",
       "999  jk#s#quarantine#be#over#yaaay#have#fun#outside...       1.0\n",
       "\n",
       "[2500 rows x 2 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-stroke",
   "metadata": {},
   "source": [
    "def whitespace_indicator(text):\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        tokens.append(token)\n",
    "    \n",
    "    return \"#\".join(tokens)\n",
    "df = df_storage\n",
    "df.text = df.text.apply(whitespace_indicator)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-december",
   "metadata": {},
   "source": [
    "### Split training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "promising-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = list(df['text'])\n",
    "y = list(df['polarity'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-sister",
   "metadata": {},
   "source": [
    "### Create vectorizer using n-grams (n = 2 ~ 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-termination",
   "metadata": {},
   "source": [
    "Note that we do not remove stop words, as previous experiments show that removing stop words (even with a customized stopword list that preserves negation words) has a small but harmful effect on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "naked-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create a bag of words for n = 2 - 5\n",
    "cv = CountVectorizer(analyzer = 'char',ngram_range=(2,5))\n",
    "\n",
    "# convert training data to bag of words\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-variable",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "special-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.7648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# train naive bayes classifier\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train_cv, y_train)\n",
    "\n",
    "# create predictions\n",
    "y_pred = clf_nb.predict(X_test_cv)\n",
    "\n",
    "# find f-1 score\n",
    "score = f1_score(y_test, y_pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fundamental-audience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7744017066937035, 0.7661108607480847, 0.7632850241545894, None)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-interview",
   "metadata": {},
   "source": [
    "### Logistic Regression (MaxEnt) classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "defensive-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.7776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# train maxent (logistic)\n",
    "clf_lr = LogisticRegression(random_state=0, max_iter=250)\n",
    "clf_lr.fit(X_train_cv, y_train)\n",
    "\n",
    "# create predictions\n",
    "y_pred = clf_lr.predict(X_test_cv)\n",
    "\n",
    "# find f-1 score\n",
    "score = f1_score(y_test, y_pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "architectural-prague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7776753712237583, 0.7777151870211807, 0.7775977226006794, None)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-impossible",
   "metadata": {},
   "source": [
    "Now that training of both classifiers are done, we should move on to test the classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-variable",
   "metadata": {},
   "source": [
    "### Test using labeled data that are used in training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-function",
   "metadata": {},
   "source": [
    "To examine the classifiers on sentiment classification only, we only choose the data entries with sentiment. Subjectivity classifiers are examined in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "korean-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply preprocessing on test data\n",
    "df_manual.text = df_manual.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "banner-safety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes#in#the#right#circumstance#there#be#a#case#...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>governance#and#executive#assistant#remotejob#r...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnbcmakeit#for#all#those#who#be#new#to#this#wo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>currently#down#with#covid#admin#two#neighbour#...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when#hire#talent#especially#remote#talent#your...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>for#all#those#who#be#new#to#this#work#from#hom...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>full#stack#web#developer#remotework#remotejob#wfh</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>where#will#collaboration#tool#for#hybridwork#g...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>africafactszone#I#m#defend#the#corruption#sa#p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>jk#s#quarantine#be#over#yaaay#have#fun#outside...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  polarity\n",
       "0    yes#in#the#right#circumstance#there#be#a#case#...       1.0\n",
       "1    governance#and#executive#assistant#remotejob#r...       0.0\n",
       "2    cnbcmakeit#for#all#those#who#be#new#to#this#wo...       0.0\n",
       "3    currently#down#with#covid#admin#two#neighbour#...       1.0\n",
       "4    when#hire#talent#especially#remote#talent#your...       0.0\n",
       "..                                                 ...       ...\n",
       "995  for#all#those#who#be#new#to#this#work#from#hom...       0.0\n",
       "996  full#stack#web#developer#remotework#remotejob#wfh       0.0\n",
       "997  where#will#collaboration#tool#for#hybridwork#g...       0.0\n",
       "998  africafactszone#I#m#defend#the#corruption#sa#p...       1.0\n",
       "999  jk#s#quarantine#be#over#yaaay#have#fun#outside...       1.0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-fraction",
   "metadata": {},
   "source": [
    "df_manual = df_store_manual\n",
    "df_manual.text = df_manual.text.apply(whitespace_indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-collaboration",
   "metadata": {},
   "source": [
    "#### Multinomial NB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "increased-portfolio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.879\n"
     ]
    }
   ],
   "source": [
    "test = list(df_manual['text'])\n",
    "ref = list(df_manual['polarity'])\n",
    "test_cv = cv.transform(test)\n",
    "pred = clf_nb.predict(test_cv)\n",
    "\n",
    "#df_test['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "comparative-liberia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.87      0.89       582\n",
      "         1.0       0.83      0.89      0.86       418\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.87      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-project",
   "metadata": {},
   "source": [
    "#### Logistic Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "difficult-pierce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.9\n"
     ]
    }
   ],
   "source": [
    "pred = clf_lr.predict(test_cv)\n",
    "\n",
    "#df_test['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "right-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.91      0.91       582\n",
      "         1.0       0.88      0.89      0.88       418\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-external",
   "metadata": {},
   "source": [
    "It seems that both classifiers score high in this test. \n",
    "\n",
    "Previous tests have shown that the scores may vary +/- 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-typing",
   "metadata": {},
   "source": [
    "### Test using labeled data that are not used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "established-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_json(\"manually_label_samples_test_labeled.json\", orient='record')\n",
    "\n",
    "df5.loc[df5.sentiment==-1,'sentiment']=4\n",
    "df5.loc[df5.sentiment==0,'polarity']=1\n",
    "df5.loc[df5.sentiment==4,'polarity']=1\n",
    "df5.loc[df5.sentiment==2,'polarity']=0\n",
    "\n",
    "df5 = df5[['text', 'polarity']].copy()\n",
    "df5.text = df5.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-connectivity",
   "metadata": {},
   "source": [
    "df5 = df_store_5\n",
    "df5.text = df5.text.apply(whitespace_indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-personal",
   "metadata": {},
   "source": [
    "#### Multinomial NB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "congressional-preliminary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.7125\n"
     ]
    }
   ],
   "source": [
    "test = list(df5['text'])\n",
    "ref = list(df5['polarity'])\n",
    "test_cv = cv.transform(test)\n",
    "pred = clf_nb.predict(test_cv)\n",
    "\n",
    "#df5['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "public-roman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.74      0.76       244\n",
      "         1.0       0.62      0.67      0.65       156\n",
      "\n",
      "    accuracy                           0.71       400\n",
      "   macro avg       0.70      0.71      0.70       400\n",
      "weighted avg       0.72      0.71      0.71       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-observation",
   "metadata": {},
   "source": [
    "#### Logistic Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "unusual-grade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.71\n"
     ]
    }
   ],
   "source": [
    "pred = clf_lr.predict(test_cv)\n",
    "\n",
    "#df5['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "subjective-harmony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.79      0.77       244\n",
      "         1.0       0.64      0.59      0.61       156\n",
      "\n",
      "    accuracy                           0.71       400\n",
      "   macro avg       0.69      0.69      0.69       400\n",
      "weighted avg       0.71      0.71      0.71       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-monte",
   "metadata": {},
   "source": [
    "### Test using every labeled data in COVID topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "continuous-wilson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes#in#the#right#circumstance#there#be#a#case#...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>governance#and#executive#assistant#remotejob#r...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnbcmakeit#for#all#those#who#be#new#to#this#wo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>currently#down#with#covid#admin#two#neighbour#...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when#hire#talent#especially#remote#talent#your...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>do#you#know#1#3#of#the#we#population#be#age#50...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>I#wait#for#bee#to#get#home#from#work#so#I#can#...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>n#ppl#really#boutta#debate#where#covid#23#come...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>least#we#dinnae#droon#folk#fir#mess#aboot#with...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>new#remote#job#staff#it#product#manager#remote...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  polarity\n",
       "0    yes#in#the#right#circumstance#there#be#a#case#...       1.0\n",
       "1    governance#and#executive#assistant#remotejob#r...       0.0\n",
       "2    cnbcmakeit#for#all#those#who#be#new#to#this#wo...       0.0\n",
       "3    currently#down#with#covid#admin#two#neighbour#...       1.0\n",
       "4    when#hire#talent#especially#remote#talent#your...       0.0\n",
       "..                                                 ...       ...\n",
       "395  do#you#know#1#3#of#the#we#population#be#age#50...       0.0\n",
       "396  I#wait#for#bee#to#get#home#from#work#so#I#can#...       0.0\n",
       "397  n#ppl#really#boutta#debate#where#covid#23#come...       0.0\n",
       "398  least#we#dinnae#droon#folk#fir#mess#aboot#with...       0.0\n",
       "399  new#remote#job#staff#it#product#manager#remote...       0.0\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_manual, df5]\n",
    "df_test = pd.concat(frames)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-corporation",
   "metadata": {},
   "source": [
    "#### Multinomial NB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "proprietary-generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.8314\n"
     ]
    }
   ],
   "source": [
    "test = list(df_test['text'])\n",
    "ref = list(df_test['polarity'])\n",
    "test_cv = cv.transform(test)\n",
    "pred = clf_nb.predict(test_cv)\n",
    "\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "exceptional-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.83      0.85       826\n",
      "         1.0       0.78      0.83      0.80       574\n",
      "\n",
      "    accuracy                           0.83      1400\n",
      "   macro avg       0.83      0.83      0.83      1400\n",
      "weighted avg       0.83      0.83      0.83      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-adams",
   "metadata": {},
   "source": [
    "#### Logistic Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "laughing-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 score : 0.8457\n"
     ]
    }
   ],
   "source": [
    "pred = clf_lr.predict(test_cv)\n",
    "\n",
    "#df5['predicted_polarity'] = pred\n",
    "score = f1_score(ref, pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "protecting-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.87      0.87       826\n",
      "         1.0       0.82      0.81      0.81       574\n",
      "\n",
      "    accuracy                           0.85      1400\n",
      "   macro avg       0.84      0.84      0.84      1400\n",
      "weighted avg       0.85      0.85      0.85      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ref, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-officer",
   "metadata": {},
   "source": [
    "### Now, classify the crawled data and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "dense-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_json(\"cleaned_data.json\", orient='record')\n",
    "clean_df.text= clean_df.text.apply(preprocess)\n",
    "X = list(clean_df['text'])\n",
    "X_cv = cv.transform(X)\n",
    "pred = clf_nb.predict(X_cv)\n",
    "polarity = pred.tolist()\n",
    "clean_df_1 = clean_df\n",
    "clean_df_1 = clean_df_1.assign(polarity = polarity)\n",
    "clean_df_1.to_csv(\"classfied_data_pol_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "stable-purple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>keyword</th>\n",
       "      <th>geo</th>\n",
       "      <th>withheld</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-02 17:54:23+00:00</td>\n",
       "      <td>15066159</td>\n",
       "      <td>march#to#june#will#be#a#bit#sparse#for#sightin...</td>\n",
       "      <td>1510314716178046976</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-02 17:47:49+00:00</td>\n",
       "      <td>292619181</td>\n",
       "      <td>alan#interview#prime#minister#boris#johnson#an...</td>\n",
       "      <td>1510313065589481472</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-02 17:44:12+00:00</td>\n",
       "      <td>15720519</td>\n",
       "      <td>how#to#talk#to#your#kid#about#school#shooting#...</td>\n",
       "      <td>1510312154284630016</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-02 17:42:46+00:00</td>\n",
       "      <td>1280441028064018432</td>\n",
       "      <td>fat#loss#in#a#week#weight#loss#for#free#traini...</td>\n",
       "      <td>1510311792698101760</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-02 17:34:58+00:00</td>\n",
       "      <td>1449377983211450368</td>\n",
       "      <td>make#a#name#get#a#check#merchandise#royality#d...</td>\n",
       "      <td>1510309831005069312</td>\n",
       "      <td>en</td>\n",
       "      <td>[#lockdown, lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66857</th>\n",
       "      <td>2022-04-02 05:00:19+00:00</td>\n",
       "      <td>1307968835694125056</td>\n",
       "      <td>goddessphotosau#sure#do#a#new#hobby#come#out#o...</td>\n",
       "      <td>1510119915801309184</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66858</th>\n",
       "      <td>2022-04-02 05:00:01+00:00</td>\n",
       "      <td>2269577210</td>\n",
       "      <td>5#determine#the#strategy#for#pandemic#manageme...</td>\n",
       "      <td>1510119841281228800</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66859</th>\n",
       "      <td>2022-04-02 04:59:59+00:00</td>\n",
       "      <td>3493412003</td>\n",
       "      <td>an#old#story#but#think#about#this#again#now#th...</td>\n",
       "      <td>1510119833366675456</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66860</th>\n",
       "      <td>2022-04-02 04:59:53+00:00</td>\n",
       "      <td>1301866054839185408</td>\n",
       "      <td>tax#oz#even#then#his#wa#covid#0#forever#lockdo...</td>\n",
       "      <td>1510119806930145280</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66861</th>\n",
       "      <td>2022-04-02 04:59:42+00:00</td>\n",
       "      <td>370445156</td>\n",
       "      <td>observation#of#an#insomniac#live#on#a#main#roa...</td>\n",
       "      <td>1510119759643578368</td>\n",
       "      <td>en</td>\n",
       "      <td>[lockdown]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66862 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at            author_id  \\\n",
       "0     2022-04-02 17:54:23+00:00             15066159   \n",
       "1     2022-04-02 17:47:49+00:00            292619181   \n",
       "2     2022-04-02 17:44:12+00:00             15720519   \n",
       "3     2022-04-02 17:42:46+00:00  1280441028064018432   \n",
       "4     2022-04-02 17:34:58+00:00  1449377983211450368   \n",
       "...                         ...                  ...   \n",
       "66857 2022-04-02 05:00:19+00:00  1307968835694125056   \n",
       "66858 2022-04-02 05:00:01+00:00           2269577210   \n",
       "66859 2022-04-02 04:59:59+00:00           3493412003   \n",
       "66860 2022-04-02 04:59:53+00:00  1301866054839185408   \n",
       "66861 2022-04-02 04:59:42+00:00            370445156   \n",
       "\n",
       "                                                    text                   id  \\\n",
       "0      march#to#june#will#be#a#bit#sparse#for#sightin...  1510314716178046976   \n",
       "1      alan#interview#prime#minister#boris#johnson#an...  1510313065589481472   \n",
       "2      how#to#talk#to#your#kid#about#school#shooting#...  1510312154284630016   \n",
       "3      fat#loss#in#a#week#weight#loss#for#free#traini...  1510311792698101760   \n",
       "4      make#a#name#get#a#check#merchandise#royality#d...  1510309831005069312   \n",
       "...                                                  ...                  ...   \n",
       "66857  goddessphotosau#sure#do#a#new#hobby#come#out#o...  1510119915801309184   \n",
       "66858  5#determine#the#strategy#for#pandemic#manageme...  1510119841281228800   \n",
       "66859  an#old#story#but#think#about#this#again#now#th...  1510119833366675456   \n",
       "66860  tax#oz#even#then#his#wa#covid#0#forever#lockdo...  1510119806930145280   \n",
       "66861  observation#of#an#insomniac#live#on#a#main#roa...  1510119759643578368   \n",
       "\n",
       "      lang                keyword  geo withheld  polarity  \n",
       "0       en  [#lockdown, lockdown]  NaN      NaN       1.0  \n",
       "1       en  [#lockdown, lockdown]  NaN      NaN       0.0  \n",
       "2       en  [#lockdown, lockdown]  NaN      NaN       0.0  \n",
       "3       en  [#lockdown, lockdown]  NaN      NaN       0.0  \n",
       "4       en  [#lockdown, lockdown]  NaN      NaN       0.0  \n",
       "...    ...                    ...  ...      ...       ...  \n",
       "66857   en             [lockdown]  NaN      NaN       1.0  \n",
       "66858   en             [lockdown]  NaN      NaN       0.0  \n",
       "66859   en             [lockdown]  NaN      NaN       1.0  \n",
       "66860   en             [lockdown]  NaN      NaN       1.0  \n",
       "66861   en             [lockdown]  NaN      NaN       0.0  \n",
       "\n",
       "[66862 rows x 9 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-identity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
